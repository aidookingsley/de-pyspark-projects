{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48f134fc",
   "metadata": {},
   "source": [
    "\n",
    "Employee Salary Imputation Analysis\n",
    "\n",
    "Problem Statement:\n",
    "This script addresses missing salary data in employee records by:\n",
    "1. Calculating department-level average salaries\n",
    "2. Imputing missing salaries using department averages\n",
    "3. Providing complete compensation analysis across departments\n",
    "\n",
    "Data Sources:\n",
    "- Employee Data: Contains salary information with missing values\n",
    "- Department Data: Department names and IDs for categorization\n",
    "\n",
    "Key Enhancements:\n",
    "- Robust missing data handling using coalesce\n",
    "- Department-level salary benchmarks\n",
    "- Clean data integration with proper joins\n",
    "- Rounded financial figures for reporting\n",
    "\n",
    "Business Applications:\n",
    "- Payroll processing with incomplete data\n",
    "- Departmental budget planning\n",
    "- Compensation fairness analysis\n",
    "- HR analytics for salary benchmarking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed3ced33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/25 01:39:44 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+--------+--------------------+----------+\n",
      "|employee_id|     name|  salary|     department_name|avg_salary|\n",
      "+-----------+---------+--------+--------------------+----------+\n",
      "|          1| Kingsley|90000.00|    Cloud Architects|  85000.00|\n",
      "|          2|  Richard|69000.00|Database Administ...|  69000.00|\n",
      "|          3| Virginia|80000.00|    Cloud Architects|  85000.00|\n",
      "|          4|    Mercy|65000.00|Networking Engineers|  65000.00|\n",
      "|          5|    Irene|75000.00|Database Administ...|  69000.00|\n",
      "|          6|Nathaniel|85000.00|    Cloud Architects|  85000.00|\n",
      "|          7|  Vanessa|65000.00|Networking Engineers|  65000.00|\n",
      "|          8|   Robert|61000.00|Database Administ...|  69000.00|\n",
      "|          9|   Birago|65000.00|Networking Engineers|  65000.00|\n",
      "|         10|    Yasir|71000.00|Database Administ...|  69000.00|\n",
      "+-----------+---------+--------+--------------------+----------+\n",
      "\n",
      "=== Complete Salary Analysis ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------------+-------------+\n",
      "|     department_name|avg_final_salary|imputed_count|\n",
      "+--------------------+----------------+-------------+\n",
      "|    Cloud Architects|        85000.00|            1|\n",
      "|Database Administ...|        69000.00|            1|\n",
      "|Networking Engineers|        65000.00|            3|\n",
      "+--------------------+----------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import avg, coalesce, round, col, when, count\n",
    "from pyspark.sql.types import DecimalType\n",
    "\n",
    "# Create a Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"SalaryDataImputation\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Sample Annual Salary for Azubi employees \n",
    "employee_data = [\n",
    "    (1, \"Kingsley\", 90000, 10),\n",
    "    (2, \"Richard\", None, 20),  # Missing salary\n",
    "    (3, \"Virginia\", 80000, 10),\n",
    "    (4, \"Mercy\", None, 30),  # Missing salary\n",
    "    (5, \"Irene\", 75000, 20),\n",
    "    (6, \"Nathaniel\", None, 10), # Missing salary\n",
    "    (7, \"Vanessa\", 65000, 30),\n",
    "    (8, \"Robert\", 61000, 20),\n",
    "    (9, \"Birago\", None, 30),  # Missing salary\n",
    "    (10, \"Yasir\", 71000, 20)\n",
    "]\n",
    "\n",
    "employee_columns = [\"employee_id\", \"name\", \"salary\", \"department_id\"]\n",
    "\n",
    "# Sample data for departments\n",
    "department_data = [\n",
    "    (10, \"Cloud Architects\"),\n",
    "    (20, \"Database Administrators\"),\n",
    "    (30, \"Networking Engineers\")  \n",
    "]\n",
    "\n",
    "department_columns = [\"department_id\", \"department_name\"]\n",
    "\n",
    "# Create DataFrames with explicit decimal precision for financial data\n",
    "employee_df = spark.createDataFrame(employee_data, employee_columns) \\\n",
    "    .withColumn(\"salary\", col(\"salary\").cast(DecimalType(10,2))\n",
    ")\n",
    "\n",
    "department_df = spark.createDataFrame(department_data, department_columns)\n",
    "\n",
    "# 1. Calculate average salary by department and round it to 2 decimal places\n",
    "avg_salary_df = employee_df.groupBy(\"department_id\") \\\n",
    "    .agg(round(avg(\"salary\"), 2).alias(\"avg_salary\")) \\\n",
    "    .withColumn(\"avg_salary\", col(\"avg_salary\").cast(DecimalType(10, 2)))\n",
    "\n",
    "# 2. Join employee DataFrame with department DataFrame\n",
    "joined_df = employee_df.join(department_df, \"department_id\", \"left\") \\\n",
    "    .join(avg_salary_df, \"department_id\", \"left\") \n",
    "\n",
    "\n",
    "# 3. Fill missing salary values with additional quality checks\n",
    "filled_df = joined_df.withColumn(\n",
    "    \"salary\",\n",
    "    coalesce(col(\"salary\"), col(\"avg_salary\"))\n",
    ").select(\n",
    "    \"employee_id\", \n",
    "    \"name\", \n",
    "    \"salary\", \n",
    "    \"department_name\",\n",
    "    \"avg_salary\"\n",
    ")\n",
    "filled_df.show()\n",
    "\n",
    "# 4. Add salary comparison metrics\n",
    "final_df = filled_df.withColumn(\n",
    "    \"salary_status\",\n",
    "    when(col(\"salary\") == col(\"avg_salary\"), \"Imputed\") \\\n",
    "    .otherwise(\"Original\")\n",
    ")\n",
    "\n",
    "# Show Comprehensive result\n",
    "print(\"=== Complete Salary Analysis ===\")\n",
    "final_df.groupBy(\"department_name\") \\\n",
    "    .agg(\n",
    "        round(avg(\"salary\"), 2).alias(\"avg_final_salary\"),\n",
    "        count(when(col(\"salary_status\") == \"Imputed\", 1)).alias(\"imputed_count\"),\n",
    ").show()\n",
    "\n",
    "# Stop the Spark session\n",
    "spark.stop()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sptfy-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
